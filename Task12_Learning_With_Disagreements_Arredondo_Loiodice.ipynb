{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task12_Exploration_Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabyA1999/GabyA1999.github.io/blob/master/Task12_Learning_With_Disagreements_Arredondo_Loiodice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilu5w4YqcMPa",
        "outputId": "d3366071-2a5f-4213-8fc0-4340e792ff6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "# install all required packages here\n",
        "# import pandas and required packages here\n",
        "!pip install transformers\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 20.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=31fb0c53925a165510a00c85c1c1af446fb937a6470c1b63d4cf574c83541898\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YPBveD1c2PP"
      },
      "source": [
        "**Load in the Dataset Here**\n",
        "This will be just the trial data that has been released so far"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWiwyE2imDLn",
        "outputId": "49eddec8-ddbc-4e09-d8bc-292b419ff3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVbdv-dGlNIS"
      },
      "source": [
        "input_file = '/content/gdrive/My Drive/NLP_Task/pdis_traindata.jsonlines'\n",
        "\n",
        "with open(input_file) as f: \n",
        "    lines = f.read().splitlines()\n",
        "\n",
        "#inter function will only have one column w/ each json in row\n",
        "df_inter = pd.DataFrame(lines) \n",
        "df_inter.columns = ['json_element']\n",
        "\n",
        "#Json.load -> decoder function \n",
        "df_inter['json_element'].apply(json.loads)\n",
        "\n",
        "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoyJ7k1Lr2yn",
        "outputId": "2d2de91f-6ec8-4783-ffd0-5bfac521227d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(df_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             gu/aesopa10cl.sentences  ... wi/Guru_meditation.mentions_annotations.(1096, 1102).2f2daf19a49f4999784e56a8b960e870\n",
            "0  [[A, Peacock, once, placed, a, petition, befor...  ...                                                [0]                                   \n",
            "\n",
            "[1 rows x 603170 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjuO7zyMcwDW"
      },
      "source": [
        "X = pd.DataFrame() #input features - this should be a dataframe of size |X|*d (|X| is number of examples and d is the number of features)\n",
        "y = pd.DataFrame() #output labels - the format of this depends on the task\n",
        "# if a task has multiple subtasks, then make y_subtaskA, y_subtaskB, etc."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "035oH8gyv6Ex"
      },
      "source": [
        "**Pre-process the input text using BertTokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhaOdRUwDfw"
      },
      "source": [
        "X['text'].map() # you will probably need to change the column name. Map is a great funciton to use here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52zt64t7wtDB"
      },
      "source": [
        "**Apply Bert Classifier (either sentence level, token level, or regression based model) to the data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td3uci0Nw8DO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4sg8zFgw-EZ"
      },
      "source": [
        "**Compute Metric (accuracy, precision, F1) on the Zero-shot trial data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJV-TUiDxF-I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovqBEDbRxHDY"
      },
      "source": [
        "**Data Exploration**\n",
        "\n",
        "Sample 10-20 examples. Do you agree with the labels in these examples? If not, why not? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7kZF93xaEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPsHbG1oxamX"
      },
      "source": [
        "Add any other findings or thoughts about the examples in a text box below."
      ]
    }
  ]
}